## Staffusion
* Introuced in 2022 - from German (HH - Those who get it , get it)
* Text - Image ( helps in creating a image from the text prompt you give to it)
    * Diffusion model is a generative model
    * Learn probability distribution from the data , so that we can sample from distribution to create a new image (which dont exist)
    * **Why distributions ?** 
        * Example - Criminal wants to create fake identity (age and height)
            * Gather the statistics of the information of the all the people , and draw the probability distributions
            * So we have the distributions for the **age** and **height**
            * We sample from these distributions (means - how we sample ?)
                * **Approach - 1**
                    * Take random from the **age** and **height** , which could be your possible fake identity
                    * But they can be random and not make sense
                * **Approach - 2** (Joint Distribution)
                    * As **age** and **height** are dependent variables , we have to consider them as joint distribution .
                    * Choose from the joint distribution - to model something 
                    * This is what we do with our images too
                    * Each `pixel is a distribution` , and entirity of all the pixels is a **Large Joint Distribution**
                        * **Marginalizing**
                            * Lets say x = height and y = age , then we can calculate the p(x) , over all the ages 
                            * This is using the `Conditional Prrobability`
    * **Goal**
        * Our data as a very big **Gaint Distribution**
        * Use NN to learn the complex distribution
        * Sample from the complex distribution to generate the **fake data**
    * **Latent Variable**
        * *Forward/Diffusion Process* - Original image to a noise image
            * We have our initial image 
            * Add some noise to the image , and generate another image , same as the previous but with some noise
            * Take the new image and add some more noise to it , generate another image with even more noise
            * Repeat the process upto 1000+ steps (Full noise image)
            * This process is `Fixed` , and a standard process to do this
        * *Reverse Process*
            * But the reverse is not possible  , so we train a NN to do this
            * The reverse process  , is done by the NN
    * **Maths for Staffusion**
        * The next state of the noise image , is generated by a bayessian relation between the states
        * Refer to slides for better understanding  (Credit - Umar Jamil)
        * We can also go from original image , to a image at a time stamp `t` , by sampling from the distribution .
    * **ELBO** 
        * In case of the age example , for the theif to calculate the optimal value or the best fake identity 
        * We made it possible using the *Marginalization*
        * Now if we consider all the latent features and , to *Marginalize* over all the latent features is too *complex* to compute
        * So to learn the value of `p(x)` , in this case we defined **Evidence Lower Bound** , is defined as the *lower bound* for the likelihood (for `p(x)`)
        * So if we maximize the *Lower Bound* , it also maximizes the *Likelihood*
            * Same logic of ,if we maximizes the sales , we are maximizing the revenue
        * Simply - To do the *reverse process* , we have to detect on `how much noise is in the noisified version of the image at time stamp t ` ,
    * **Inference**
        * Now we know how to do a *forward process*
        * We also have a network that helps in *reverse process*
            * `Detect how much noise is in the image at a given time stamp t`
        * Start from the noisy end 
        * Give the newtork complete noise
        * Ask the netwrk on how much noise and remove the noise 
        * We get the image for the previous time stamp
        * So on we go on repeating the process of removing noise taht is detected from the network , we trained for the *reverse process* , Until we reach the original image stage , with a new image .
        * We have to control , the **Denoisification** so we can generate the images we want .
            * Control the denoisification , to generate the new image we are generating , so
            * We introduce a *prompt* / *Conditioning Signal* / *Context* , to influence the model and generate the image we want
            * How to introduce the prompt ?
    * Our final goal is to get the maximize the Likelihood , which we are maximizing using the ELBO , and minimizing the loss
        * Wht is the loss ?
            * Loss function indicates that we need to create a model f , so that this funciton predicts the amount of noise at a particlar step t .
            * GD on the training loop to learn the loss computed
            * But the model doesnt know of the relation between the image and what image represents
    * Learning Context of the data
        * **Approach - 1** (Combine the image and context at the time of training)
            * Joint distribution over the inital data(images) and the conditioning signals (P(X,C))
            * Not so helpfull as we are trying to mariginalize (find P(X)) , and we dont have to depend much on the context C
            * So we dont use the joint over the images and the context together , to not let the generative nature of the output generated die
        * **Approach - 2**
            * How to condition then ?
            * We build the model f(above mentioned) , using the **U-net**
            * *Unet* , get the noisified input , at a parituclar time stamp
            * The *Unet* has to identify the noise at the particular time stamp
            * Also pass the *prompt* with the noisified input , model now gets more information on what is important
            * Model learns on how to remove the *noise* , on the basis of *prompt*  ,and that is what is learnt by the model 
            * Now the model becomes the *conditioned* model 
                * Some times in some time stamps , we could not give the *prompt*
                * This makes the model both *conditioned* and *un-conditioned*
    * **Inference flow - Classifier free guidence**
        * Step - 1 
            * Start from pure noise at time stamp (T = 1000) , maximum noise
            * We also give the *prompt* to the Unet
            * Predict the noise , that we need to remove , to move the input towards the output we want (say `cat`)
        * Step - 2
            * Same start from the pure noise and time stamp (T = 1000) , maximum noise
            * This case we *no prompt* is given to the Unet
            * Predict the noise, that we need to remove , to move the input towards the output (can be anything)
        * Step - 3
            * From the output of *step-1* and *step-2*
            * we can decide how much the outpt to be closer to the prompt
        * Train a model ,  sometimes give prompt , sometimes no prompt , so model learns to pay attention and ignore the prompt
            * **output = w*(output_condiutioned - output_unconditioned) + output_conditioned**
            * Larger the value of *difference* , more the output is aligned with the *prompt*
    * **CLIP - Contrastive Language - Image Pre-training**
        * To understand the prompt , the model needs some king of embedding 
        * *Embedding* - The vector that represent the embedding of the word
        * These *Embedding* are extracted using the *CLIP* text Encoder
            * Allows to connect the text with images
        * Loss funcition , with diagonal with maximum value and the other numbers to be `zero`
        * Model learnt , how to combine the description of the image with the image itseld
        * Use the trained encoder , of the *CLIP* and these embeddings could be used as **Conditioning Signal** for our Unet to **denoise** into what we want
    * **Limitation of Unet**
        * If the image is too large (512*512) , we have to compute very big matrix , very slow
        * Compress the image into something **Smaller** , using the **Variational Auto Encoder**
    * **Latenet Diffusion Model**
        * The **Stable Diffusion** is also called as **Latent Diffusion Model**
        * As we dont learn the data , but we learn the *latent representation of the data*
        * We compress the data , smaller, and learn the *compressed verison* of the data
        * And rebuild it from the compressed version to build the required output
            * Example - Send the file as **Zip and UnZip** the file at the reciving end (intution of auto encoder)
            * The latent space , through decoder , to build it back
            * More the noise you add , more you can change the Unet model
            * Less noise , less is were able to change our model

    
